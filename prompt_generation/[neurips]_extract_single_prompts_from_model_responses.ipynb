{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Seed Only - Claude\n",
        "import json\n",
        "import re\n",
        "# Load the JSON content\n",
        "with open(\"claude_SO_bias_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "all_prompts = []\n",
        "rows = []\n",
        "\n",
        "# Flatten prompts from all context items\n",
        "for prompt_id, text in data.items():\n",
        "        # Use regex to find all prompt entries labeled as \"Prompt x\"\n",
        "        matches = re.findall(r\"(?:\\*\\*|#)?Prompt\\s*\\d+\\**:?\\s*\\\"(.*?)\\\"\", text, re.DOTALL)\n",
        "        if matches:\n",
        "            for prompt in matches:\n",
        "                single_line = ' '.join(prompt.strip().split())\n",
        "                all_prompts.append(single_line)\n",
        "                rows.append({\n",
        "                    'Prompt_ID': prompt_id,\n",
        "                    'Prompt': prompt\n",
        "                })\n",
        "        else:\n",
        "            # If prompts are not quoted, try bullet point/colon pattern\n",
        "            alt_matches = re.findall(r\"(?:\\*\\*|#)?Prompt\\s*\\d+\\**:?\\s*(.*)\", text)\n",
        "            for prompt in alt_matches:\n",
        "                # Remove emojis or decode them to ensure compatibility\n",
        "                cleaned = ' '.join(prompt.strip().split())\n",
        "                all_prompts.append(cleaned)\n",
        "                rows.append({\n",
        "                    'Prompt_ID': prompt_id,\n",
        "                    'Prompt': prompt\n",
        "                })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df\n",
        "\n",
        "df.to_json(\"claude_SO_ \" + \"bias\" + \"_extracted_singles.json\", orient=\"records\", force_ascii=False)\n",
        "df.to_csv(\"claude_SO_ \" + \"bias\" + \"_extracted_singles.csv\", index = False)\n",
        "\n",
        "\n",
        "# # # Write to output JSON\n",
        "# with open(\"claude_SO_bias_extracted.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(result, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "42TF_i-hDRKs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Seed Only - All other models\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_prompts_from_block(text):\n",
        "    \"\"\"\n",
        "    Extracts up to 5 prompt strings from a text block using regex.\n",
        "    \"\"\"\n",
        "    patterns = [\n",
        "        # Pattern for Markdown-style header followed by text\n",
        "        r'##\\s*Prompt\\s*\\d+:\\s*\\n(.*?)(?=\\n##\\s*Justification:|$)',\n",
        "\n",
        "        # Pattern for 'Prompt X': followed by text\n",
        "        r\"'Prompt\\s*\\d+':\\s*(.*?)\\s*'Justification':\",\n",
        "\n",
        "        # Pattern for Markdown-style header followed by quoted or bolded text\n",
        "        r'###\\s*Prompt\\s*\\d+:\\s*\\n[\"“](.*?)[\"”]|\\*\\*(.*?)\\*\\*',\n",
        "\n",
        "        # Pattern for Markdown-style header followed by plain text\n",
        "        r'###\\s*Prompt\\s*\\d+:\\s*\\n(.*?)\\n\\*\\*Justification:',\n",
        "\n",
        "        # Pattern for **1. \"Prompt\": followed by text\n",
        "        r'\\*\\*\\d+\\.\\s*\"Prompt\":\\s*(.*?)\\s*Justification:',\n",
        "\n",
        "        # Pattern for \"Prompt\": followed by quoted text\n",
        "        r'\"Prompt\":\\s*(.*?)\\s*(?=\"Justification\":)',\n",
        "\n",
        "        # Pattern for Prompt X: followed by text on the same line\n",
        "        r'Prompt\\s*\\d+:\\s*(.*?)\\s*Justification:',\n",
        "\n",
        "        # Pattern for Prompt X: followed by text on the next line\n",
        "        r'Prompt\\s*\\d+:\\s*\\n(.*?)\\nJustification:',\n",
        "\n",
        "        # Pattern for Prompt X: with quoted text, handling multiline quotes\n",
        "        r'Prompt\\s*\\d+:\\s*[\"“](.*?)[\"”](?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **1. Prompt** style with bold\n",
        "        r'\\*\\*\\d+\\.\\s*Prompt\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for *Prompt* style with asterisks\n",
        "        r'\\*Prompt\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **'Prompt X'** style with bold and single quotes\n",
        "        r'\\*\\*\\'Prompt\\s*\\d+\\'\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **1. 'Prompt'** style with bold and single quotes\n",
        "        r'\\*\\*\\d+\\.\\s*\\'Prompt\\'\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **'Prompt'** style with bold and single quotes\n",
        "        r'\\*\\*\\'Prompt\\'\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **Prompt** without quotes\n",
        "        r'\\*\\*Prompt\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **Prompt X:** followed by quoted or unquoted text\n",
        "        r'^\\s*\\*\\*Prompt\\s*\\d*[:\\*]*\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for other prompt styles without explicit **Prompt: prefix\n",
        "        r'^\\s*\\d+\\.\\s*[\"\\'“”]?(.*?)[\"\\'“”]?\\s*$',\n",
        "\n",
        "        # Generic pattern for capturing any line starting with **Prompt:\n",
        "        r'\\*\\*Prompt:\\*\\*\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for 'Prompt' key style\n",
        "        r'\\'Prompt\\'\\s*:\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Another generic pattern\n",
        "        r'\\bPrompt:\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **Prompt X**: \"text\"\n",
        "        r'\\*\\*Prompt\\s*\\d+\\*\\*:\\s*\"(.*?)\"',\n",
        "\n",
        "        # Pattern for **Prompt X**: 'text'\n",
        "        r'\\*\\*Prompt\\s*\\d+\\*\\*:\\s*\\'(.*?)\\'',\n",
        "\n",
        "        # Pattern for Prompt X: \"text\"\n",
        "        r'Prompt\\s*\\d+:\\s*\"(.*?)\"',\n",
        "\n",
        "        # Pattern for Prompt X: 'text'\n",
        "        r'Prompt\\s*\\d+:\\s*\\'(.*?)\\'',\n",
        "    ]\n",
        "\n",
        "    prompts = []\n",
        "    for pattern in patterns:\n",
        "        matches = re.findall(pattern, text, flags=re.MULTILINE)\n",
        "        for match in matches:\n",
        "            # Some patterns produce a single capturing group, others produce two groups.\n",
        "            if isinstance(match, tuple):\n",
        "                # If it's the pattern with quotes ([\\'\"]), the second group is the extracted prompt text.\n",
        "                cleaned = match[1]\n",
        "            else:\n",
        "                cleaned = match\n",
        "\n",
        "            # Strip away extra quotes or special characters around the text\n",
        "            # cleaned = cleaned.strip('\"“”\\' ').strip()\n",
        "\n",
        "            if cleaned and cleaned not in prompts:\n",
        "                prompts.append(cleaned)\n",
        "            if len(prompts) >= 5:\n",
        "                break\n",
        "        if len(prompts) >= 5:\n",
        "            break\n",
        "\n",
        "    return prompts[:5]\n",
        "\n",
        "def extract_prompts_to_df(data):\n",
        "    \"\"\"\n",
        "    Converts nested dict {prompt_id: {attack_strategy: block}} to a flat DataFrame\n",
        "    with Prompt_ID, Attack_Strategy, Prompt columns.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for prompt_id, text in data.items():\n",
        "            prompts = extract_prompts_from_block(text)\n",
        "            # if prompts == []:\n",
        "            #   print(text)\n",
        "            # #   print(prompts)\n",
        "            for prompt in prompts:\n",
        "                if prompt.lower() == 'prompt' or prompt.lower() == 'prompt 1' or prompt.lower() == 'prompt 2' or prompt.lower() == 'prompt 3' or prompt.lower() == 'prompt 4' or prompt.lower() == 'prompt 5':\n",
        "                    continue\n",
        "                elif prompt.lower() == 'justification':\n",
        "                    continue\n",
        "                else:\n",
        "                  rows.append({\n",
        "                      'Prompt_ID': prompt_id,\n",
        "                      'Prompt': prompt\n",
        "                  })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# input_fname = 'claude_bias_extracted_prompts.json'\n",
        "# with open(input_fname, 'r', encoding='utf-8') as f:\n",
        "#     data = json.load(f)\n",
        "#     f.close()\n",
        "\n",
        "# extracted_df = extract_prompts_to_df(data)\n",
        "# len(extracted_df)\n",
        "# extracted_df\n",
        "\n",
        "import os\n",
        "\n",
        "fnames = os.listdir('/content/')\n",
        "fnames.remove('.config')\n",
        "fnames.remove('sample_data')\n",
        "fnames.remove('.ipynb_checkpoints')\n",
        "fnames.remove('json_prompts')\n",
        "fnames.remove('csv_prompts')\n",
        "\n",
        "for fname in fnames:\n",
        "  print(fname)\n",
        "  model, _, failure, _ = fname.split('_')\n",
        "  with open(fname, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "    f.close()\n",
        "  extracted_df = extract_prompts_to_df(data)\n",
        "  json_dir = '/content/json_prompts/'\n",
        "  extracted_df.to_json(json_dir + model + '_' + failure + \"_extracted_singles.json\", orient=\"records\", force_ascii=False)\n",
        "  csv_dir = '/content/csv_prompts/'\n",
        "  extracted_df.to_csv(csv_dir + model + '_' + failure + \"_extracted_singles.csv\", index = False)\n",
        "\n",
        "!zip -r json_prompts.zip json_prompts\n",
        "!zip -r csv_prompts.zip csv_prompts\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK3JvTd_VBKN",
        "outputId": "8a1136a3-8a66-4c50-a4a0-cefc86b0477e",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4.1_SO_violent_1.json\n",
            "gpt-4.1_SO_hate_1.json\n",
            "llama_SO_bias_1.json\n",
            "gpt-4.1_SO_sexual_1.json\n",
            "gemini_SO_sexual_1.json\n",
            "gemini_SO_bias_1.json\n",
            "gpt-4.1_SO_bias_1.json\n",
            "gemini_SO_violent_1.json\n",
            "llama_SO_violent_1.json\n",
            "gemini_SO_hate_1.json\n",
            "llama_SO_sexual_1.json\n",
            "llama_SO_hate_1.json\n",
            "  adding: json_prompts/ (stored 0%)\n",
            "  adding: json_prompts/gpt-4.1_violent_extracted_singles.json (deflated 77%)\n",
            "  adding: json_prompts/llama_hate_extracted_singles.json (deflated 80%)\n",
            "  adding: json_prompts/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: json_prompts/gemini_violent_extracted_singles.json (deflated 73%)\n",
            "  adding: json_prompts/gemini_bias_extracted_singles.json (deflated 72%)\n",
            "  adding: json_prompts/gemini_hate_extracted_singles.json (deflated 71%)\n",
            "  adding: json_prompts/gemini_sexual_extracted_singles.json (deflated 72%)\n",
            "  adding: json_prompts/gpt-4.1_sexual_extracted_singles.json (deflated 78%)\n",
            "  adding: json_prompts/llama_bias_extracted_singles.json (deflated 81%)\n",
            "  adding: json_prompts/gpt-4.1_bias_extracted_singles.json (deflated 78%)\n",
            "  adding: json_prompts/llama_violent_extracted_singles.json (deflated 81%)\n",
            "  adding: json_prompts/llama_sexual_extracted_singles.json (deflated 80%)\n",
            "  adding: json_prompts/gpt-4.1_hate_extracted_singles.json (deflated 76%)\n",
            "  adding: csv_prompts/ (stored 0%)\n",
            "  adding: csv_prompts/gpt-4.1_SO_extracted_singles.csv (deflated 76%)\n",
            "  adding: csv_prompts/gemini_hate_extracted_singles.csv (deflated 66%)\n",
            "  adding: csv_prompts/llama_sexual_extracted_singles.csv (deflated 78%)\n",
            "  adding: csv_prompts/gpt-4.1_violent_extracted_singles.csv (deflated 75%)\n",
            "  adding: csv_prompts/gpt-4.1_bias_extracted_singles.csv (deflated 76%)\n",
            "  adding: csv_prompts/gpt-4.1_sexual_extracted_singles.csv (deflated 76%)\n",
            "  adding: csv_prompts/llama_SO_extracted_singles.csv (deflated 78%)\n",
            "  adding: csv_prompts/llama_bias_extracted_singles.csv (deflated 79%)\n",
            "  adding: csv_prompts/gpt-4.1_hate_extracted_singles.csv (deflated 74%)\n",
            "  adding: csv_prompts/gemini_SO_extracted_singles.csv (deflated 66%)\n",
            "  adding: csv_prompts/gemini_bias_extracted_singles.csv (deflated 68%)\n",
            "  adding: csv_prompts/llama_violent_extracted_singles.csv (deflated 79%)\n",
            "  adding: csv_prompts/gemini_violent_extracted_singles.csv (deflated 68%)\n",
            "  adding: csv_prompts/gemini_sexual_extracted_singles.csv (deflated 68%)\n",
            "  adding: csv_prompts/llama_hate_extracted_singles.csv (deflated 78%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Hybrid - Claude, Llama, GPT, Gemini\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_prompts_from_block(text):\n",
        "    \"\"\"\n",
        "    Extracts up to 5 prompt strings from a text block using regex.\n",
        "    \"\"\"\n",
        "    patterns = [\n",
        "        # Pattern for Markdown-style header followed by text\n",
        "        r'##\\s*Prompt\\s*\\d+:\\s*\\n(.*?)(?=\\n##\\s*Justification:|$)',\n",
        "\n",
        "        # Pattern for 'Prompt X': followed by text\n",
        "        r\"'Prompt\\s*\\d+':\\s*(.*?)\\s*'Justification':\",\n",
        "\n",
        "        # Pattern for Markdown-style header followed by quoted or bolded text\n",
        "        r'###\\s*Prompt\\s*\\d+:\\s*\\n[\"“](.*?)[\"”]|\\*\\*(.*?)\\*\\*',\n",
        "\n",
        "        # Pattern for Markdown-style header followed by plain text\n",
        "        r'###\\s*Prompt\\s*\\d+:\\s*\\n(.*?)\\n\\*\\*Justification:',\n",
        "\n",
        "        # Pattern for **1. \"Prompt\": followed by text\n",
        "        r'\\*\\*\\d+\\.\\s*\"Prompt\":\\s*(.*?)\\s*Justification:',\n",
        "\n",
        "        # Pattern for \"Prompt\": followed by quoted text\n",
        "        r'\"Prompt\":\\s*(.*?)\\s*(?=\"Justification\":)',\n",
        "\n",
        "        # Pattern for Prompt X: followed by text on the same line\n",
        "        r'Prompt\\s*\\d+:\\s*(.*?)\\s*Justification:',\n",
        "\n",
        "        # Pattern for Prompt X: followed by text on the next line\n",
        "        r'Prompt\\s*\\d+:\\s*\\n(.*?)\\nJustification:',\n",
        "\n",
        "        # Pattern for Prompt X: with quoted text, handling multiline quotes\n",
        "        r'Prompt\\s*\\d+:\\s*[\"“](.*?)[\"”](?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **1. Prompt** style with bold\n",
        "        r'\\*\\*\\d+\\.\\s*Prompt\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for *Prompt* style with asterisks\n",
        "        r'\\*Prompt\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **'Prompt X'** style with bold and single quotes\n",
        "        r'\\*\\*\\'Prompt\\s*\\d+\\'\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **1. 'Prompt'** style with bold and single quotes\n",
        "        r'\\*\\*\\d+\\.\\s*\\'Prompt\\'\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **'Prompt'** style with bold and single quotes\n",
        "        r'\\*\\*\\'Prompt\\'\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **Prompt** without quotes\n",
        "        r'\\*\\*Prompt\\*\\*:\\s*(.*?)\\s*(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **Prompt X:** followed by quoted or unquoted text\n",
        "        r'^\\s*\\*\\*Prompt\\s*\\d*[:\\*]*\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for other prompt styles without explicit **Prompt: prefix\n",
        "        r'^\\s*\\d+\\.\\s*[\"\\'“”]?(.*?)[\"\\'“”]?\\s*$',\n",
        "\n",
        "        # Generic pattern for capturing any line starting with **Prompt:\n",
        "        r'\\*\\*Prompt:\\*\\*\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for 'Prompt' key style\n",
        "        r'\\'Prompt\\'\\s*:\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Another generic pattern\n",
        "        r'\\bPrompt:\\s*[\"\\'“”]?(.*?)[\"\\'“”]?(?:\\n|\\r|$)',\n",
        "\n",
        "        # Pattern for **Prompt X**: \"text\"\n",
        "        r'\\*\\*Prompt\\s*\\d+\\*\\*:\\s*\"(.*?)\"',\n",
        "\n",
        "        # Pattern for **Prompt X**: 'text'\n",
        "        r'\\*\\*Prompt\\s*\\d+\\*\\*:\\s*\\'(.*?)\\'',\n",
        "\n",
        "        # Pattern for Prompt X: \"text\"\n",
        "        r'Prompt\\s*\\d+:\\s*\"(.*?)\"',\n",
        "\n",
        "        # Pattern for Prompt X: 'text'\n",
        "        r'Prompt\\s*\\d+:\\s*\\'(.*?)\\'',\n",
        "    ]\n",
        "\n",
        "    prompts = []\n",
        "    for pattern in patterns:\n",
        "        matches = re.findall(pattern, text, flags=re.MULTILINE)\n",
        "        for match in matches:\n",
        "            # Some patterns produce a single capturing group, others produce two groups.\n",
        "            if isinstance(match, tuple):\n",
        "                # If it's the pattern with quotes ([\\'\"]), the second group is the extracted prompt text.\n",
        "                cleaned = match[1]\n",
        "            else:\n",
        "                cleaned = match\n",
        "\n",
        "            # Strip away extra quotes or special characters around the text\n",
        "            # cleaned = cleaned.strip('\"“”\\' ').strip()\n",
        "\n",
        "            if cleaned and cleaned not in prompts:\n",
        "                prompts.append(cleaned)\n",
        "            if len(prompts) >= 5:\n",
        "                break\n",
        "        if len(prompts) >= 5:\n",
        "            break\n",
        "\n",
        "    return prompts[:5]\n",
        "\n",
        "def extract_prompts_to_df(data):\n",
        "    \"\"\"\n",
        "    Converts nested dict {prompt_id: {attack_strategy: block}} to a flat DataFrame\n",
        "    with Prompt_ID, Attack_Strategy, Prompt columns.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for prompt_id, strategies in data.items():\n",
        "        for attack_strategy, text in strategies.items():\n",
        "            prompts = extract_prompts_from_block(text)\n",
        "            # if prompts == []:\n",
        "            #   print(text)\n",
        "            # #   print(prompts)\n",
        "            for prompt in prompts:\n",
        "                if prompt.lower() == 'prompt' or prompt.lower() == 'prompt 1' or prompt.lower() == 'prompt 2' or prompt.lower() == 'prompt 3' or prompt.lower() == 'prompt 4' or prompt.lower() == 'prompt 5':\n",
        "                    continue\n",
        "                elif prompt.lower() == 'justification':\n",
        "                    continue\n",
        "                else:\n",
        "                  rows.append({\n",
        "                      'Prompt_ID': prompt_id,\n",
        "                      'Attack_Strategy': attack_strategy,\n",
        "                      'Prompt': prompt\n",
        "                  })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# input_fname = 'claude_bias_extracted_prompts.json'\n",
        "# with open(input_fname, 'r', encoding='utf-8') as f:\n",
        "#     data = json.load(f)\n",
        "#     f.close()\n",
        "\n",
        "# extracted_df = extract_prompts_to_df(data)\n",
        "# len(extracted_df)\n",
        "# extracted_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lCBUA2AR_cFz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Zip extracted .json and .csv files for easy export\n",
        "import os\n",
        "\n",
        "fnames = os.listdir('/content/')\n",
        "fnames.remove('.config')\n",
        "fnames.remove('sample_data')\n",
        "fnames.remove('.ipynb_checkpoints')\n",
        "fnames.remove('json_prompts')\n",
        "fnames.remove('csv_prompts')\n",
        "\n",
        "for fname in fnames:\n",
        "  print(fname)\n",
        "  model, failure, _, _ = fname.split('_')\n",
        "  with open(fname, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "    f.close()\n",
        "  extracted_df = extract_prompts_to_df(data)\n",
        "  json_dir = '/content/json_prompts/'\n",
        "  extracted_df.to_json(json_dir + model + '_' + failure + \"_extracted_singles.json\", orient=\"records\", force_ascii=False)\n",
        "  csv_dir = '/content/csv_prompts/'\n",
        "  extracted_df.to_csv(csv_dir + model + '_' + failure + \"_extracted_singles.csv\", index = False)\n",
        "\n",
        "!zip -r json_prompts.zip json_prompts\n",
        "!zip -r csv_prompts.zip csv_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z2Rt2pzkPAkN",
        "outputId": "9c0b2f3d-7627-45ce-d5b2-6afd18854666",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gemini_bias_extracted_prompts.json\n",
            "llama_hate_extracted_prompts.json\n",
            "gemini_hate_extracted_prompts.json\n",
            "gpt-4.1_sexual_extracted_prompts.json\n",
            "gemini_sexual_extracted_prompts.json\n",
            "claude_sexual_extracted_prompts.json\n",
            "llama_bias_extracted_prompts.json\n",
            "gemini_violent_extracted_prompts.json\n",
            "claude_hate_extracted_prompts.json\n",
            "claude_violent_extracted_prompts.json\n",
            "gpt-4.1_violent_extracted_prompts.json\n",
            "llama_sexual_extracted_prompts.json\n",
            "llama_violent_extracted_prompts.json\n",
            "claude_bias_extracted_prompts.json\n",
            "gpt-4.1_bias_extracted_prompts.json\n",
            "gpt-4.1_hate_extracted_prompts.json\n"
          ]
        }
      ]
    }
  ]
}