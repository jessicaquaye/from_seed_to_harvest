PRE-PROCESSING
1. The master file which was downloaded from the Adversarial Nibbler Dataset. All rounds have been compiled together into one large file. Then it is deduplicated using dedup-comprehensive.py

2. The indices are split based on the failure mode annotations provided by participants using split_indices_into_failure_modes.py

3. In order to subsample, we first select 250 prompts from the hate folder (category with the least number of annotations - select_pids_unique_users.py). Then we recursively  select 250 prompts for each of the other categories (bias, hate, sexual, violent) - after_hate_select_others.py. This generates 4 .json files containing the indices that we will use for our experiments: violent_selected_pids.json, sexual_selected_pids.json, hate_selected_pids.json, bias_selected_pids.json. 

PROMPT GENERATION
1. There are 3 different techniques that we implement and evaluate:
- From Seed to Harvest Hybrid (provide both seed prompt and attack strategy guidance to model)
- Attack Only Strategy (provide only direction on attack strategy but no seed prompt)
- Seed Only Strategy (provide only seed prompt and ask model to creatively expand without any attack strategy guidance)

The code pertaining to each of these techniques will be stored in a folder with the following structure: hybrid/ , AO/, SO/

2. The directory for each of these techniques contains 4 python files which contain code for calling 4 different LLMs that are used to generate new prompts. They all have some format [neurips] generate_prompts_using_claude.py, [neurips] generate_prompts_using_gpt4.py, [neurips] generate_prompts_using_gemini.py, [neurips] generate_prompts_using_llama.py . 

3. After all new prompts are generated by the LLMs, we pattern match the ("Prompt": , "Justification") structure to extract the prompts listed in the string  - [neurips] extract_single_prompts_from_model_responses.ipynb

4. For each original prompt, we combine all the responses from the different LLMs and select the 4 most diverse prompts for use in our experiments - [neurips] combine_and_select_top_4_responses.ipynb. 

IMAGE GENERATION

With our "image-generation-ready" prompts, we generate images using the following T2I models - DALL-E 2, Stable Diffusion (SD) VAE, SD 1.5, SD XL, SD XL Turbo. We streamlined all the stable diffusion calls through one python file [] and multiple .sh files []. The DALL-E generations also take place on a remote cluster in [].

EVALUATION

1. Image Safety Classification
Upon completion, each of the images are put through the 
NudeNet Classifier - nudenet_detector.py
Stable Diffusion NSFW Classifier - sd_nsfw.py
Q16 Classifier - q16.py

Then we tally the output to calculate the Average Attack Success Rate - [neurips] tally_classifier_output.ipynb

2. Prompt Diversity Calculation - [neurips] calculate_shannon_entropy.ipynb
We also calculate the Shannon Entropy of our geographic and demographic diversity using a two step process: 
(i) Use the spaCy NLP library to extract entities of type GPE (Geo-Political Entity) and NORP (Nationalities or Religious or Political groups).

(ii) After mapping each sentence to a list of entities (e.g., "France", "India", etc.), we compute their Shannon entropy. 



